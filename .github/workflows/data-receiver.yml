name: Data Receiver

on:
  push:
    paths:
      - '.github/triggers/*.json'
  repository_dispatch:
    types: [data_update]
  workflow_dispatch:
    inputs:
      trigger_type:
        description: 'Trigger type'
        required: false
        default: 'manual'
        type: string

concurrency:
  group: data-receiver-${{ github.ref }}
  cancel-in-progress: false

jobs:
  process-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.HEALTHMETRIC_TOKEN }}
        # Checkout the latest commit on main branch to get the most recent triggers
        ref: main
        fetch-depth: 1

    - name: Create trigger from repository_dispatch payload
      if: github.event_name == 'repository_dispatch'
      run: |
        echo "Creating trigger from repository_dispatch payload..."
        mkdir -p .github/triggers
        
        # Create trigger file from dispatch payload
        cat > .github/triggers/dispatch_trigger_$(date +%s).json << 'EOF'
        ${{ toJSON(github.event.client_payload) }}
        EOF
        
        echo "✓ Trigger created from dispatch event"
        cat .github/triggers/dispatch_trigger_*.json
    
    - name: Pre-check triggers present in workspace
      id: precheck
      run: |
        echo "Pre-checking triggers in workspace..."
        echo "Event: ${{ github.event_name }}"
        ls -la .github || true
        ls -la .github/triggers || true
        TRIGGER_COUNT=$(ls .github/triggers/*.json 2>/dev/null | wc -l || true)
        echo "Found $TRIGGER_COUNT trigger file(s) in workspace."
        if [ "${TRIGGER_COUNT:-0}" -gt 0 ]; then
          echo "has_triggers=true" >> $GITHUB_OUTPUT
        else
          echo "has_triggers=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests PyGithub
    
    - name: Run data receiver
      env:
        GITHUB_TOKEN: ${{ secrets.HEALTHMETRIC_TOKEN }}
      run: |
        python receiver/receiver.py --verbose

    - name: Debug listing
      if: steps.precheck.outputs.has_triggers == 'true'
      run: |
        echo "Repo root listing:" && ls -la
        echo "_data_received tree:" && ( [ -d _data_received ] && find _data_received -maxdepth 2 -type f -or -type d || echo "(none)" )
        echo "Git status:" && git status --porcelain=v1

    - name: Post-extraction empty-folder probe
      if: steps.precheck.outputs.has_triggers == 'true'
      run: |
        if [ -d _data_received ]; then
          for d in _data_received/*; do
            [ -d "$d" ] || continue
            cnt=$(find "$d" -type f | wc -l)
            if [ "$cnt" -eq 0 ]; then
              echo "Adding CI probe to $d"
              echo "ci probe $(date -u '+%Y-%m-%d %H:%M:%S UTC')" > "$d/.ci_probe"
            fi
          done
        fi

    - name: Print receiver.log
      if: steps.precheck.outputs.has_triggers == 'true' || always()
      run: |
        echo "==== receiver.log (if exists) ===="
        if [ -f receiver.log ]; then
          sed -n '1,300p' receiver.log
        else
          echo "(no receiver.log present)"
        fi

    - name: Validate extraction
      if: steps.precheck.outputs.has_triggers == 'true'
      run: |
        echo "Validating that at least one job folder exists under _data_received..."
        if [ -d _data_received ] && [ "$(find _data_received -mindepth 1 -maxdepth 1 -type d | wc -l)" -gt 0 ]; then
          echo "Extraction folder(s) present."
        else
          echo "No extracted job folders detected under _data_received" >&2
          exit 1
        fi

    - name: Write probe file
      run: |
        mkdir -p _data_received
        echo "probe $(date -u '+%Y-%m-%d %H:%M:%S UTC')" > _data_received/_pipeline_probe.txt

    - name: Stage all changes (data + triggers)
      if: steps.precheck.outputs.has_triggers == 'true'
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        # Stage extracted data
        git add -A _data_received || true
        # Stage archived triggers
        git add -A .github/triggers_processed || true
        # Stage removed triggers
        git add -A .github/triggers || true
    
    - name: Check for changes
      if: steps.precheck.outputs.has_triggers == 'true'
      id: changes
      run: |
        if [ -n "$(git diff --cached --name-only)" ]; then
          echo "changes=true" >> $GITHUB_OUTPUT
          echo "Changed files:"
          git diff --cached --name-only
        else
          echo "changes=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Commit and push all changes in single commit
      if: steps.precheck.outputs.has_triggers == 'true' && steps.changes.outputs.changes == 'true'
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        # Create single commit with all changes
        git commit -m "chore: process data and manage triggers [skip ci]

        - Extract and process incoming data files
        - Archive processed triggers
        - Clean up temporary files" || echo "No changes to commit"
        # Pull latest changes before pushing to avoid conflicts
        git pull origin main --rebase
        git push origin main
    
    - name: Create processing summary
      if: always()
      run: |
        echo "## Data Processing Summary" > processing_summary.md
        echo "" >> processing_summary.md
        echo "**Trigger:** ${{ github.event_name }}" >> processing_summary.md
        echo "**Time:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> processing_summary.md
        echo "**Commit:** ${{ github.sha }}" >> processing_summary.md
        echo "" >> processing_summary.md
        
        if [ -d "_data_received" ]; then
          echo "### Jobs Created:" >> processing_summary.md
          find _data_received -maxdepth 1 -type d -printf "- %f\n" | tail -n +2 >> processing_summary.md
        fi
        
        echo "" >> processing_summary.md
        echo "### Workflow Details:" >> processing_summary.md
        echo "- **Repository:** ${{ github.repository }}" >> processing_summary.md
        echo "- **Branch:** ${{ github.ref_name }}" >> processing_summary.md
        echo "- **Actor:** ${{ github.actor }}" >> processing_summary.md
    
    - name: Upload processing logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: processing-logs
        path: |
          receiver.log
          processing_summary.md
        retention-days: 7
    
    - name: Comment on commit (if triggered by push)
      if: github.event_name == 'push' && github.event.head_commit
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          let summary = '## Data Processing Complete ✅\n\n';
          
          try {
            if (fs.existsSync('processing_summary.md')) {
              summary += fs.readFileSync('processing_summary.md', 'utf8');
            } else {
              summary += 'Data processing completed successfully.';
            }
          } catch (error) {
            summary += `Error reading summary: ${error.message}`;
          }
          
          github.rest.repos.createCommitComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            commit_sha: context.sha,
            body: summary
          });
